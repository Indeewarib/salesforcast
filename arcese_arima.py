# -*- coding: utf-8 -*-
"""arcece.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14yds9WnRy2kl81bCYSN3FjQnm3wPJExh
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os

full_path = os.path.realpath(__file__)
project_folder = os.path.dirname(full_path) 

route_sale_df = pd.read_excel(f'{project_folder}\\Input_data_timeseries.xlsx', parse_dates=['ORDER DATE'])
route_sale_df.head()

route_sale_df.isnull().sum().sum()

route_sale_df.dtypes

type('ORDER DATE')

route_sale_df.describe()

route_sale_df['ORDER DATE'] = pd.to_datetime(route_sale_df['ORDER DATE'])

df_weekly = (route_sale_df.groupby([pd.Grouper(key='ORDER DATE', freq='W'), 'ROUTE'])['NUMBER OF ACTUAL ORDERS'].sum().reset_index())
df_weekly.rename(columns={'ORDER DATE': 'WEEK', 'NUMBER OF ACTUAL ORDERS': 'WEEKLY ORDERS'}, inplace=True)
df_weekly['WEEK'] = pd.to_datetime(df_weekly['WEEK'], errors='coerce')

#df_weekly.set_index('WEEK', inplace=True)

df_weekly

df_weekly.dtypes

import pandas as pd
from statsmodels.tsa.stattools import adfuller
from sklearn.model_selection import train_test_split

# Assuming 'df_weekly' is your dataframe with columns 'ROUTE', 'DATE', 'WEEKLY ORDERS'

routes = df_weekly['ROUTE'].unique()  # Get unique routes

# Create separate training, validation, and test sets per route
train_set = []
val_set = []
test_set = []

# Lists to store stationary and non-stationary routes
stationary_routes = []
non_stationary_routes = []

for route in routes:
    route_data = df_weekly[df_weekly['ROUTE'] == route]

    # Split each route's data into 60% train, 20% validation, and 20% test
    train, temp = train_test_split(route_data, test_size=0.4, shuffle=False)
    val, test = train_test_split(temp, test_size=0.5, shuffle=False)

    train_set.append(train)
    val_set.append(val)
    test_set.append(test)

    # Step to check stationarity for each route's training data
    result = adfuller(route_data['WEEKLY ORDERS'])
    print(f"Stationarity Test for Route {route}:")
    print('ADF Statistic:', result[0])
    print('p-value:', result[1])

    # Check if the series is stationary and categorize
    if result[1] > 0.05:
        print(f"The series for route {route} is not stationary. Differencing may be required.")
        non_stationary_routes.append(route)  # Add to non-stationary list
    else:
        print(f"The series for route {route} is stationary.")
        stationary_routes.append(route)  # Add to stationary list

# Combine all data splits back into separate dataframes
train_df = pd.concat(train_set)
val_df = pd.concat(val_set)
test_df = pd.concat(test_set)

# Print summary of stationary and non-stationary routes
print("\nStationary Routes:")
print(stationary_routes)

print("\nNon-Stationary Routes:")
print(non_stationary_routes)

# Check the number of records in each split for each route
train_sizes = train_df.groupby('ROUTE').size()
val_sizes = val_df.groupby('ROUTE').size()
test_sizes = test_df.groupby('ROUTE').size()

# Display the sizes of the splits
print("Training set size per route:\n", train_sizes)
print("\nValidation set size per route:\n", val_sizes)
print("\nTest set size per route:\n", test_sizes)

# Preview the first few rows of each set
print("Training set preview:")
print(train_df.head())

print("\nValidation set preview:")
print(val_df.head())

print("\nTest set preview:")
print(test_df.head())

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10,6))
sns.lineplot(data=df_weekly, x='WEEK', y='WEEKLY ORDERS')
plt.title("Orders over Time")
plt.show()

import pandas as pd
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.stattools import adfuller
from sklearn.model_selection import train_test_split

# Assuming df_weekly is your dataframe with 'ROUTE', 'DATE', 'WEEKLY ORDERS'

# List of routes
stationary_routes = ['BELGIUM__BELGIUM', 'BELGIUM__EAST_BALCAN', 'BELGIUM__GERMANY_RUHR', 'BELGIUM__GREAT_BRITAIN', 'BELGIUM__ITALY_NORTH_EAST_CENTER',
                     'BELGIUM__ITALY_NORTH_WEST', 'BELGIUM__ITALY_SOUTH', 'BELGIUM__ROMANIA', 'BELGIUM__SCANDINAVIA', 'EAST_BALCAN__BELGIUM',
                     'EAST_BALCAN__ITALY_NORTH_EAST_CENTER', 'EAST_NORTH__EAST_NORTH', 'EAST_NORTH__GERMANY_RUHR', 'EAST_NORTH__ITALY_NORTH_EAST_CENTER',
                     'EAST_NORTH__ITALY_SOUTH', 'FRANCE__FRANCE', 'FRANCE__GERMANY_NORTH', 'FRANCE__ITALY_NORTH_EAST_CENTER', 'FRANCE__ITALY_NORTH_WEST',
                     'FRANCE__ITALY_SOUTH', 'GERMANY_NORTH__ITALY_NORTH_EAST_CENTER', 'GERMANY_NORTH__ITALY_NORTH_WEST', 'GERMANY_RUHR__BELGIUM',
                     'GERMANY_RUHR__EAST_NORTH', 'GERMANY_RUHR__GREAT_BRITAIN', 'GERMANY_RUHR__IBERIA', 'GERMANY_RUHR__ITALY_NORTH_EAST_CENTER',
                     'GERMANY_RUHR__ITALY_NORTH_WEST', 'GERMANY_RUHR__ITALY_SOUTH', 'GERMANY_RUHR__ROMANIA', 'GERMANY_RUHR__SCANDINAVIA',
                     'GERMANY_SOUTH__ITALY_NORTH_EAST_CENTER', 'GERMANY_SOUTH__ITALY_NORTH_WEST', 'GERMANY_SOUTH__ITALY_SOUTH',
                     'GERMANY_SOUTH__SCANDINAVIA', 'GREAT_BRITAIN__BELGIUM', 'GREAT_BRITAIN__FRANCE', 'GREAT_BRITAIN__GERMANY_RUHR',
                     'GREAT_BRITAIN__GREAT_BRITAIN', 'GREAT_BRITAIN__ITALY_NORTH_EAST_CENTER', 'GREAT_BRITAIN__ITALY_NORTH_WEST', 'IBERIA__BELGIUM',
                     'IBERIA__GERMANY_RUHR', 'IBERIA__IBERIA', 'IBERIA__ITALY_NORTH_EAST_CENTER', 'IBERIA__ITALY_NORTH_WEST', 'IBERIA__ITALY_SOUTH',
                     'ITALY_NORTH_EAST_CENTER__BELGIUM', 'ITALY_NORTH_EAST_CENTER__EAST_BALCAN', 'ITALY_NORTH_EAST_CENTER__EAST_NORTH',
                     'ITALY_NORTH_EAST_CENTER__FRANCE', 'ITALY_NORTH_EAST_CENTER__GERMANY_NORTH', 'ITALY_NORTH_EAST_CENTER__GREAT_BRITAIN',
                     'ITALY_NORTH_EAST_CENTER__IBERIA', 'ITALY_NORTH_EAST_CENTER__ITALY_NORTH_EAST_CENTER', 'ITALY_NORTH_EAST_CENTER__ITALY_NORTH_WEST',
                     'ITALY_NORTH_EAST_CENTER__ITALY_SOUTH', 'ITALY_NORTH_EAST_CENTER__ROMANIA', 'ITALY_NORTH_EAST_CENTER__SCANDINAVIA',
                     'ITALY_NORTH_WEST__EAST_BALCAN', 'ITALY_NORTH_WEST__EAST_NORTH', 'ITALY_NORTH_WEST__FRANCE', 'ITALY_NORTH_WEST__GERMANY_NORTH',
                     'ITALY_NORTH_WEST__GERMANY_RUHR', 'ITALY_NORTH_WEST__GERMANY_SOUTH', 'ITALY_NORTH_WEST__ITALY_NORTH_EAST_CENTER', 'ITALY_NORTH_WEST__ITALY_NORTH_WEST', 'ITALY_NORTH_WEST__ITALY_SOUTH', 'ITALY_NORTH_WEST__SCANDINAVIA', 'ITALY_SOUTH__BELGIUM', 'ITALY_SOUTH__EAST_NORTH', 'ITALY_SOUTH__FRANCE', 'ITALY_SOUTH__GERMANY_RUHR', 'ITALY_SOUTH__GERMANY_SOUTH', 'ITALY_SOUTH__GREAT_BRITAIN', 'ITALY_SOUTH__IBERIA', 'ITALY_SOUTH__ITALY_NORTH_EAST_CENTER', 'ITALY_SOUTH__ITALY_SOUTH', 'ITALY_SOUTH__SCANDINAVIA', 'ROMANIA__BELGIUM', 'ROMANIA__GREAT_BRITAIN', 'ROMANIA__ITALY_NORTH_WEST', 'SCANDINAVIA__ITALY_NORTH_EAST_CENTER', 'SCANDINAVIA__ITALY_NORTH_WEST', 'SCANDINAVIA__ITALY_SOUTH']  # Example stationary routes
non_stationary_routes = ['EAST_BALCAN__ITALY_NORTH_WEST', 'EAST_NORTH__ITALY_NORTH_WEST',
                          'FRANCE__GERMANY_RUHR', 'GERMANY_RUHR__FRANCE', 'GERMANY_RUHR__GERMANY_RUHR',
                          'ITALY_NORTH_EAST_CENTER__GERMANY_RUHR', 'ITALY_NORTH_EAST_CENTER__GERMANY_SOUTH',
                          'ITALY_NORTH_WEST__BELGIUM', 'ITALY_NORTH_WEST__GREAT_BRITAIN',
                          'ITALY_NORTH_WEST__IBERIA', 'ITALY_SOUTH__ITALY_NORTH_WEST',
                          'ROMANIA__GERMANY_RUHR', 'SCANDINAVIA__BELGIUM']  # Example non-stationary routes

# Function to split data and check stationarity
def split_and_check_stationarity(route_data):
    # Split data into 60% train, 20% validation, 20% test
    train, temp = train_test_split(route_data, test_size=0.4, shuffle=False)
    val, test = train_test_split(temp, test_size=0.5, shuffle=False)

    # Check for stationarity using ADF test
    result = adfuller(train['WEEKLY ORDERS'])
    if result[1] > 0.05:  # If p-value > 0.05, the series is non-stationary
        train['WEEKLY ORDERS'] = train['WEEKLY ORDERS'].diff().dropna()

    return train, val, test, result[1] > 0.05  # Return differenced data and stationarity status

# Function to fit ARIMA model
def fit_arima_model(train_data):
    # Fit ARIMA model (p=5, d=1, q=0 as example)
    model = ARIMA(train_data['WEEKLY ORDERS'], order=(5, 1, 0))
    model_fit = model.fit()
    return model_fit

# Loop through each route and process
for route in stationary_routes + non_stationary_routes:
    route_data = df_weekly[df_weekly['ROUTE'] == route]

    # Split the data and check stationarity
    train_set, val_set, test_set, is_non_stationary = split_and_check_stationarity(route_data)

    # Fit ARIMA model for each route
    print(f"Fitting ARIMA model for route {route}")
    model_fit = fit_arima_model(train_set)

    # Print model summary for each route
    print(f"ARIMA Model Summary for {route}:")
    print(model_fit.summary())

    # If necessary, apply differencing on validation and test sets
    if is_non_stationary:
        val_set['WEEKLY ORDERS'] = val_set['WEEKLY ORDERS'].diff().dropna()
        test_set['WEEKLY ORDERS'] = test_set['WEEKLY ORDERS'].diff().dropna()

    # Evaluate model performance on validation and test sets (you could use RMSE, MAE, etc. for this)
    # Example: forecast and compare with actual
    forecast = model_fit.forecast(steps=len(val_set))
    print(f"Validation set predictions for {route}: {forecast}")
    print(f"Validation set actuals for {route}: {val_set['WEEKLY ORDERS'].values}")







"""# **Q2**

"""

# Convert 'ORDER DATE' to datetime
route_sale_df['ORDER DATE'] = pd.to_datetime(route_sale_df['ORDER DATE'])

# Group by week and route, summing the 'NUMBER OF ACTUAL ORDERS'
df_weekly = route_sale_df.groupby([pd.Grouper(key='ORDER DATE', freq='W'), 'ROUTE'])['NUMBER OF ACTUAL ORDERS'].sum().reset_index()

# Rename columns appropriately
df_weekly.rename(columns={'ORDER DATE': 'WEEK', 'NUMBER OF ACTUAL ORDERS': 'WEEKLY ORDERS'}, inplace=True)


# Set 'WEEK' as the index
df_weekly.set_index('WEEK', inplace=True)


# Check the result
df_weekly.head()

df_weekly.dtypes

import pandas as pd
import numpy as np
import streamlit as st
import matplotlib.pyplot as plt
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.stattools import adfuller
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.preprocessing import StandardScaler

# Scaling the data
scaler = StandardScaler()
df_weekly['SCALED_ORDERS'] = scaler.fit_transform(df_weekly[['WEEKLY ORDERS']])

# Function to split data into train, validation, and test sets
def split_data_by_route(df, route_col='ROUTE', target_col='SCALED_ORDERS', train_size=0.6, val_size=0.2):
    train_set = []
    val_set = []
    test_set = []

    routes = df[route_col].unique()

    for route in routes:
        route_data = df[df[route_col] == route]

        # Split data into train (60%), validation (20%), and test (20%)
        train, temp = train_test_split(route_data, test_size=1 - train_size, shuffle=False)
        val, test = train_test_split(temp, test_size=0.5, shuffle=False)

        train_set.append(train)
        val_set.append(val)
        test_set.append(test)

    # Combine back into single dataframes for easier handling
    train_df = pd.concat(train_set)
    val_df = pd.concat(val_set)
    test_df = pd.concat(test_set)

    return train_df, val_df, test_df

# Function to check stationarity using the ADF test
def check_stationarity(data, target_col='SCALED_ORDERS'):
    result = adfuller(data[target_col])
    if result[1] > 0.05:  # If p-value > 0.05, the series is non-stationary
        return False
    else:
        return True

# Function to apply ARIMA model
def fit_arima_model(train_data, order, target_col='SCALED_ORDERS'):
    model = ARIMA(train_data[target_col], order=order)
    model_fit = model.fit()
    return model_fit

# Function to forecast and evaluate the model on validation and test sets
def evaluate_model(model_fit, val_data, test_data, target_col='SCALED_ORDERS'):
    # Forecasting for validation and test data
    val_forecast = model_fit.forecast(steps=len(val_data))
    test_forecast = model_fit.forecast(steps=len(test_data))

    # Evaluate performance on validation and test sets
    val_mae = mean_absolute_error(val_data[target_col], val_forecast)
    test_mae = mean_absolute_error(test_data[target_col], test_forecast)
    val_rmse = np.sqrt(mean_squared_error(val_data[target_col], val_forecast))
    test_rmse = np.sqrt(mean_squared_error(test_data[target_col], test_forecast))

    return val_forecast, test_forecast, val_mae, test_mae, val_rmse, test_rmse

# Function to forecast for a specific route and plot results
def forecast_for_route(route, df, target_col='SCALED_ORDERS'):
    # Filter the data for the selected route
    route_data = df[df['ROUTE'] == route]

    # Split data into train, validation, and test sets
    train_df, val_df, test_df = split_data_by_route(route_data)

    # Check if the series is stationary
    is_stationary = check_stationarity(train_df, target_col)

    # Choose ARIMA order based on stationarity
    order = (5, 0, 3) if is_stationary else (5, 1, 3)

    if not is_stationary:
        train_df[target_col] = train_df[target_col].diff().dropna()

    model_fit = fit_arima_model(train_df, order=order)

    # Evaluate model performance on validation and test sets
    val_forecast, test_forecast, val_mae, test_mae, val_rmse, test_rmse = evaluate_model(model_fit, val_df, test_df)

    # Get the forecasted value for the next week in actual scale
    next_week_forecast = test_forecast[-1]
    next_week_forecast_actual = scaler.inverse_transform([[next_week_forecast]])[0][0]
    next_week_date = test_df.index[-1] + pd.Timedelta(weeks=1)

    # Plot the forecast vs actual for validation and test (in scaled values)
    plt.figure(figsize=(10, 6))
    plt.plot(val_df.index, val_df[target_col], label='Actual (Validation)', color='blue')
    plt.plot(val_df.index, val_forecast, label='Forecast (Validation)', color='red')
    plt.plot(test_df.index, test_df[target_col], label='Actual (Test)', color='green')
    plt.plot(test_df.index, test_forecast, label='Forecast (Test)', color='orange')
    plt.xlabel('Date')
    plt.ylabel('Scaled Orders')
    plt.title(f"Forecast vs Actual for {route}")
    plt.legend()
    st.pyplot(plt)

    # Display error metrics, stationarity information, and forecast for next week
    st.write(f"Is the series stationary? {'Yes' if is_stationary else 'No'}")
    st.write(f"Validation MAE: {val_mae:.4f}, RMSE: {val_rmse:.4f}")
    st.write(f"Test MAE: {test_mae:.4f}, RMSE: {test_rmse:.4f}")
    st.write(f"Forecasted Orders for Next Week (Week starting {next_week_date.date()}): {next_week_forecast_actual:.2f}")

# Streamlit UI
def main():
    st.title("ARIMA Forecasting for Weekly Orders")

    # Select route from the available routes in the dataset
    routes = df_weekly['ROUTE'].unique()
    selected_route = st.selectbox("Select a route to forecast:", routes)

    if selected_route:
        forecast_for_route(selected_route, df_weekly)

if __name__ == "__main__":
    main()











